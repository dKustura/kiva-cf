{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kiva collaborative filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import implicit\n",
    "from scipy.sparse import csr_matrix, lil_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "import logging\n",
    "import time\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from implicit.als import AlternatingLeastSquares\n",
    "from implicit.approximate_als import (AnnoyAlternatingLeastSquares, FaissAlternatingLeastSquares,\n",
    "                                      NMSLibAlternatingLeastSquares)\n",
    "from implicit.bpr import BayesianPersonalizedRanking\n",
    "from implicit.nearest_neighbours import (BM25Recommender, CosineRecommender,\n",
    "                                         TFIDFRecommender, bm25_weight)\n",
    "\n",
    "from implicit.datasets.movielens import get_movielens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: MKL_NUM_THREADS=1\n"
     ]
    }
   ],
   "source": [
    "%env MKL_NUM_THREADS=1\n",
    "logging.basicConfig(level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans = set()\n",
    "lenders = set()\n",
    "loans_lenders_dict = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lenders filled.\n"
     ]
    }
   ],
   "source": [
    "with open('additional-kiva-snapshot/lenders.csv', newline='', encoding=\"utf8\") as csvfile:\n",
    "    csv_reader = csv.reader(csvfile)\n",
    "    line_num = 0\n",
    "    for row in csv_reader:\n",
    "        if line_num == 0:\n",
    "            line_num += 1\n",
    "            continue\n",
    "        lenders.add(row[0])\n",
    "        line_num += 1\n",
    "\n",
    "print('Lenders filled.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loans-lenders dict filled\n"
     ]
    }
   ],
   "source": [
    "with open('additional-kiva-snapshot/loans_lenders.csv', newline='', encoding=\"utf8\") as csvfile:\n",
    "    csv_reader = csv.reader(csvfile)\n",
    "    line_num = 0\n",
    "    for row in csv_reader:\n",
    "        if line_num == 0:\n",
    "            line_num += 1\n",
    "            continue\n",
    "        loan_id, lender_ids = row\n",
    "        loans.add(loan_id)\n",
    "        loans_lenders_dict[loan_id] = set(lender_ids.split(\", \"))\n",
    "        line_num += 1\n",
    "\n",
    "print('Loans-lenders dict filled')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility matrix creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans_list = list(loans)\n",
    "lenders_list = list(lenders)\n",
    "utility_matrix = lil_matrix((len(loans), len(lenders)), dtype=np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenders_reverse_index = {k: v for v, k in enumerate(lenders_list)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filled utiility matrix\n"
     ]
    }
   ],
   "source": [
    "for loan_index, loan in enumerate(loans_list):\n",
    "    for lender in loans_lenders_dict[loan]:\n",
    "        lender_index = lenders_reverse_index[lender]\n",
    "        utility_matrix[loan_index, lender_index] = 1\n",
    "    \n",
    "print('Filled utiility matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "utility_matrix = utility_matrix.tocsr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas dataset reading\n",
    "###### (used only for visualization purposes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenders_table = pd.read_csv('additional-kiva-snapshot/lenders.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenders = lenders_table['permanent_name']\n",
    "lenders = lenders.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans_lenders_table = pd.read_csv('additional-kiva-snapshot/loans_lenders.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans = loans_lenders_table['loan_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS = {\n",
    "    \"als\":  AlternatingLeastSquares,\n",
    "    \"nmslib_als\": NMSLibAlternatingLeastSquares,\n",
    "    \"annoy_als\": AnnoyAlternatingLeastSquares,\n",
    "    \"faiss_als\": FaissAlternatingLeastSquares,\n",
    "    \"tfidf\": TFIDFRecommender,\n",
    "    \"cosine\": CosineRecommender,\n",
    "    \"bpr\": BayesianPersonalizedRanking,\n",
    "    \"bm25\": BM25Recommender\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(model_name):\n",
    "    print(\"getting model %s\" % model_name)\n",
    "    model_class = MODELS.get(model_name)\n",
    "    if not model_class:\n",
    "        raise ValueError(\"Unknown Model '%s'\" % model_name)\n",
    "\n",
    "    # some default params\n",
    "    if issubclass(model_class, AlternatingLeastSquares):\n",
    "        params = {'factors': 16, 'dtype': np.float32, 'use_gpu': True}\n",
    "    elif model_name == \"bm25\":\n",
    "        params = {'K1': 100, 'B': 0.5}\n",
    "    elif model_name == \"bpr\":\n",
    "        params = {'factors': 63}\n",
    "    else:\n",
    "        params = {}\n",
    "\n",
    "    return model_class(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model_name=\"als\", alpha=40):    \n",
    "    # create a model from the input data\n",
    "    model = get_model(model_name)\n",
    "    data_matrix = utility_matrix\n",
    "    \n",
    "    # if we're training an ALS based model, weight input by bm25\n",
    "    if issubclass(model.__class__, AlternatingLeastSquares):\n",
    "        # multiply positive inputs with alpha\n",
    "        logging.debug(\"scaling matrix by alpha\")\n",
    "        data_matrix = data_matrix.multiply(alpha)\n",
    "        \n",
    "        logging.debug(\"weighting matrix by bm25_weight\")\n",
    "        data_matrix = bm25_weight(data_matrix)\n",
    "\n",
    "        # also disable building approximate recommend index\n",
    "        model.approximate_similar_items = False\n",
    "        \n",
    "    logging.debug(\"training model %s\", model_name)\n",
    "    start = time.time()\n",
    "    model.fit(data_matrix)\n",
    "    logging.debug(\"trained model '%s' in %0.2fs\", model_name, time.time() - start)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_recommendations(model, output_filename):\n",
    "    \"\"\" Generates loan recommendations for each lender in the dataset \"\"\"\n",
    "\n",
    "    # generate recommendations for each lender and write out to a file\n",
    "    start = time.time()\n",
    "    lenders_loans = utility_matrix.T.tocsr()\n",
    "    with tqdm.tqdm(total=len(lenders)) as progress:\n",
    "        with codecs.open(output_filename, \"w\", \"utf8\") as o:\n",
    "            for lender_index, lender in enumerate(lenders_list):\n",
    "                for loan_index, score in model.recommend(lender_index, lenders_loans, N=5):\n",
    "                    o.write(\"%s\\t%s\\t%s\\n\" % (lender, loans_list[loan_index], score))\n",
    "                progress.update(1)\n",
    "    logging.debug(\"generated recommendations in %0.2fs\", time.time() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting model als\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:implicit:GPU training requires factor size to be a multiple of 32. Increasing factors from 16 to 32.\n",
      "DEBUG:root:scaling matrix by alpha\n",
      "DEBUG:root:weighting matrix by bm25_weight\n",
      "DEBUG:root:training model als\n",
      "DEBUG:implicit:Converting input to CSR format\n",
      "DEBUG:implicit:Converted input to CSR in 0.344s\n",
      "DEBUG:implicit:Calculated transpose in 3.277s\n",
      "DEBUG:implicit:Initialized factors in 2.0001230239868164\n",
      "DEBUG:implicit:Running 15 ALS iterations\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 15.0/15 [00:27<00:00,  1.76s/it]\n",
      "DEBUG:root:trained model 'als' in 36.18s\n"
     ]
    }
   ],
   "source": [
    "model = train_model(alpha=100, model_name=\"als\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_recommendations(model, \"output.tsv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This section is an usage example on the MovieLens dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles, ratings = get_movielens('20m')\n",
    "\n",
    "# remove things < min_rating, and convert to implicit dataset\n",
    "# by considering ratings as a binary preference only\n",
    "ratings.data[ratings.data < 4.0] = 0\n",
    "ratings.eliminate_zeros()\n",
    "ratings.data = np.ones(len(ratings.data))\n",
    "print(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = (bm25_weight(ratings, B=0.9) * 5).tocsr()\n",
    "print(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans_table = pd.read_csv('additional-kiva-snapshot/loans.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "funded_loans_table = loans_table[loans_table.status == 'funded']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "funded_loans = funded_loans_table['loan_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans_table.status.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The train/test splitting script is used from [here](https://gist.github.com/tgsmith61591/ce7d614d7a0442f94cd5ae5d1e51d3c2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collab_split import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "coo_mat = utility_matrix.tocoo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "users, items, ratings = coo_mat.row, coo_mat.col, coo_mat.data\n",
    "users = LabelEncoder().fit_transform(users)\n",
    "items = LabelEncoder().fit_transform(items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the train/test samples 80/20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(users, items, ratings, train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
