{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kiva collaborative filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import implicit\n",
    "from scipy.sparse import csr_matrix, lil_matrix\n",
    "\n",
    "# visualization libraries\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "import logging\n",
    "import time\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from implicit.als import AlternatingLeastSquares\n",
    "from implicit.approximate_als import (AnnoyAlternatingLeastSquares, FaissAlternatingLeastSquares,\n",
    "                                      NMSLibAlternatingLeastSquares)\n",
    "from implicit.bpr import BayesianPersonalizedRanking\n",
    "from implicit.nearest_neighbours import (BM25Recommender, CosineRecommender,\n",
    "                                         TFIDFRecommender, bm25_weight)\n",
    "\n",
    "from implicit.datasets.movielens import get_movielens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: MKL_NUM_THREADS=1\n"
     ]
    }
   ],
   "source": [
    "%env MKL_NUM_THREADS=1\n",
    "logging.basicConfig(level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans_table = pd.read_csv('additional-kiva-snapshot/loans.csv')\n",
    "loans_table = loans_table.sort_values(by='raised_time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "funded_loans_table = loans_table[loans_table.status == 'funded']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_DATE = '2017-01-01'\n",
    "END_DATE = '2019-01-01'\n",
    "\n",
    "mask = (funded_loans_table['raised_time'] > START_DATE) & (funded_loans_table['raised_time'] <= END_DATE)\n",
    "funded_loans_table = funded_loans_table.loc[mask]\n",
    "\n",
    "funded_loan_ids_set = set(funded_loans_table['loan_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('additional-kiva-snapshot/lenders.csv', newline='', encoding=\"utf8\") as csvfile:\n",
    "#     csv_reader = csv.reader(csvfile)\n",
    "#     line_num = 0\n",
    "#     for row in csv_reader:\n",
    "#         if line_num == 0:\n",
    "#             line_num += 1\n",
    "#             continue\n",
    "#         lenders.add(row[0])\n",
    "#         line_num += 1\n",
    "\n",
    "# print('Lenders filled.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loans-lenders dict filled\n",
      "Loans set filled\n",
      "Lenders set filled\n"
     ]
    }
   ],
   "source": [
    "loans = set()\n",
    "lenders = set()\n",
    "loans_lenders_dict = {}\n",
    "\n",
    "with open('additional-kiva-snapshot/loans_lenders.csv', newline='', encoding=\"utf8\") as csvfile:\n",
    "    csv_reader = csv.reader(csvfile)\n",
    "    line_num = 0\n",
    "    for row in csv_reader:\n",
    "        if line_num == 0:\n",
    "            line_num += 1\n",
    "            continue\n",
    "        loan_id, lender_ids = row\n",
    "        loan_id = int(loan_id)\n",
    "        if loan_id not in funded_loan_ids_set:\n",
    "            continue\n",
    "        \n",
    "        loans.add(loan_id)\n",
    "        new_lenders = set(lender_ids.split(\", \"))\n",
    "        loans_lenders_dict[loan_id] = new_lenders\n",
    "        lenders.update(new_lenders)\n",
    "        line_num += 1\n",
    "\n",
    "print('Loans-lenders dict filled')\n",
    "print('Loans set filled')\n",
    "print('Lenders set filled')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility matrix creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans_list = list(loans)\n",
    "lenders_list = list(lenders)\n",
    "utility_matrix = lil_matrix((len(loans), len(lenders)), dtype=np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenders_reverse_index = {k: v for v, k in enumerate(lenders_list)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filled utiility matrix\n"
     ]
    }
   ],
   "source": [
    "for loan_index, loan in enumerate(loans_list):\n",
    "    for lender in loans_lenders_dict[loan]:\n",
    "        lender_index = lenders_reverse_index[lender]\n",
    "        utility_matrix[loan_index, lender_index] = 1\n",
    "    \n",
    "print('Filled utiility matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "utility_matrix = utility_matrix.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(197221, 457022)\n"
     ]
    }
   ],
   "source": [
    "print(utility_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas dataset reading\n",
    "###### (used only for data analysis purposes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenders_table = pd.read_csv('additional-kiva-snapshot/lenders.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenders = lenders_table['permanent_name']\n",
    "lenders = lenders.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans_lenders_table = pd.read_csv('additional-kiva-snapshot/loans_lenders.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans_lenders_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS = {\n",
    "    \"als\":  AlternatingLeastSquares,\n",
    "    \"nmslib_als\": NMSLibAlternatingLeastSquares,\n",
    "    \"annoy_als\": AnnoyAlternatingLeastSquares,\n",
    "    \"faiss_als\": FaissAlternatingLeastSquares,\n",
    "    \"tfidf\": TFIDFRecommender,\n",
    "    \"cosine\": CosineRecommender,\n",
    "    \"bpr\": BayesianPersonalizedRanking,\n",
    "    \"bm25\": BM25Recommender\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(model_name):\n",
    "    print(\"getting model %s\" % model_name)\n",
    "    model_class = MODELS.get(model_name)\n",
    "    if not model_class:\n",
    "        raise ValueError(\"Unknown Model '%s'\" % model_name)\n",
    "\n",
    "    # some default params\n",
    "    if issubclass(model_class, AlternatingLeastSquares):\n",
    "        params = {'factors': 16, 'dtype': np.float32, 'use_gpu': True}\n",
    "    elif model_name == \"bm25\":\n",
    "        params = {'K1': 100, 'B': 0.5}\n",
    "    elif model_name == \"bpr\":\n",
    "        params = {'factors': 63}\n",
    "    else:\n",
    "        params = {}\n",
    "\n",
    "    return model_class(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model_name=\"als\", alpha=40):    \n",
    "    # create a model from the input data\n",
    "    model = get_model(model_name)\n",
    "    data_matrix = utility_matrix\n",
    "    \n",
    "    # if we're training an ALS based model, weight input by bm25\n",
    "    if issubclass(model.__class__, AlternatingLeastSquares):\n",
    "        # multiply positive inputs with alpha\n",
    "        logging.debug(\"scaling matrix by alpha\")\n",
    "        data_matrix = data_matrix.multiply(alpha)\n",
    "        \n",
    "        logging.debug(\"weighting matrix by bm25_weight\")\n",
    "        data_matrix = bm25_weight(data_matrix)\n",
    "\n",
    "        # also disable building approximate recommend index\n",
    "        model.approximate_similar_items = False\n",
    "        \n",
    "    logging.debug(\"training model %s\", model_name)\n",
    "    start = time.time()\n",
    "    model.fit(data_matrix)\n",
    "    logging.debug(\"trained model '%s' in %0.2fs\", model_name, time.time() - start)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_recommendations(model, output_filename, N=10):\n",
    "    \"\"\" Generates loan recommendations for each lender in the dataset \"\"\"\n",
    "\n",
    "    # generate recommendations for each lender and write out to a file\n",
    "    start = time.time()\n",
    "    lenders_loans = utility_matrix.T.tocsr()\n",
    "    with tqdm.tqdm(total=len(lenders)) as progress:\n",
    "        with codecs.open(output_filename, \"w\", \"utf8\") as o:\n",
    "            for lender_index, lender in enumerate(lenders_list):\n",
    "                for loan_index, score in model.recommend(lender_index, lenders_loans, N=N):\n",
    "                    o.write(\"%s\\t%s\\t%s\\n\" % (lender, loans_list[loan_index], score))\n",
    "                progress.update(1)\n",
    "    logging.debug(\"generated recommendations in %0.2fs\", time.time() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting model als\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:implicit:GPU training requires factor size to be a multiple of 32. Increasing factors from 16 to 32.\n",
      "DEBUG:root:scaling matrix by alpha\n",
      "DEBUG:root:weighting matrix by bm25_weight\n",
      "DEBUG:root:training model als\n",
      "DEBUG:implicit:Converting input to CSR format\n",
      "DEBUG:implicit:Converted input to CSR in 0.031s\n",
      "DEBUG:implicit:Calculated transpose in 0.109s\n",
      "DEBUG:implicit:Initialized factors in 0.31866908073425293\n",
      "DEBUG:implicit:Running 15 ALS iterations\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 15.0/15 [00:03<00:00,  4.02it/s]\n",
      "DEBUG:root:trained model 'als' in 5.49s\n"
     ]
    }
   ],
   "source": [
    "model = train_model(alpha=100, model_name=\"als\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_recommendations(model, \"output.tsv\", N=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This section is an usage example on the MovieLens dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles, ratings = get_movielens('20m')\n",
    "\n",
    "# remove things < min_rating, and convert to implicit dataset\n",
    "# by considering ratings as a binary preference only\n",
    "ratings.data[ratings.data < 4.0] = 0\n",
    "ratings.eliminate_zeros()\n",
    "ratings.data = np.ones(len(ratings.data))\n",
    "print(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = (bm25_weight(ratings, B=0.9) * 5).tocsr()\n",
    "print(ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing environment\n",
    "###### (skip for now)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The train/test splitting script is used from [here](https://gist.github.com/tgsmith61591/ce7d614d7a0442f94cd5ae5d1e51d3c2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collab_split import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coo_mat = utility_matrix.tocoo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users, items, ratings = coo_mat.row, coo_mat.col, coo_mat.data\n",
    "users = LabelEncoder().fit_transform(users)\n",
    "items = LabelEncoder().fit_transform(items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the train/test samples 80/20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(users, items, ratings, train_size=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implicit testing environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:implicit:GPU training requires factor size to be a multiple of 32. Increasing factors from 100 to 128.\n",
      "DEBUG:implicit:Calculated transpose in 0.100s\n",
      "DEBUG:implicit:Initialized factors in 1.9693121910095215\n",
      "DEBUG:implicit:Running 15 ALS iterations\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 15.0/15 [00:12<00:00,  1.25it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 457022/457022 [32:14<00:00, 236.22it/s]\n"
     ]
    }
   ],
   "source": [
    "from implicit.evaluation import precision_at_k, train_test_split\n",
    "from implicit.datasets.movielens import get_movielens\n",
    "\n",
    "# movies, ratings = get_movielens(\"20m\")\n",
    "# train, test = train_test_split(ratings)\n",
    "\n",
    "coo_mat = utility_matrix.tocoo()\n",
    "train, test = train_test_split(coo_mat)\n",
    "\n",
    "model = AlternatingLeastSquares(use_gpu=True)\n",
    "model.fit(train)\n",
    "\n",
    "precision = precision_at_k(model, train.T.tocsr(), test.T.tocsr(), K=10, num_threads=4)\n",
    "#map_measure = mean_average_precision_at_k(model, train.T.tocsr(), test.T.tocsr(), K=10, num_threads=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision @10: 0.015661\n"
     ]
    }
   ],
   "source": [
    "print('Precision @10: %f' % precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC AUC development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def calc_mean_auc(model, train_user_items, test_user_items, K=10, show_progress=True):    \n",
    "#     user_aucs = [] # An empty list to store the AUC for each user\n",
    "    \n",
    "#     for user in altered_users: # Iterate through each user that had an item altered\n",
    "#         training_row = training_set[user,:].toarray().reshape(-1) # Get the training set row\n",
    "#         zero_inds = np.where(training_row == 0) # Find where the interaction had not yet occurred\n",
    "#         # Get the predicted values based on our user/item vectors\n",
    "#         user_vec = predictions[0][user,:]\n",
    "#         pred = user_vec.dot(item_vecs).toarray()[0,zero_inds].reshape(-1)\n",
    "#         # Get only the items that were originally zero\n",
    "#         # Select all ratings from the MF prediction for this user that originally had no iteraction\n",
    "#         actual = test_set[user,:].toarray()[0,zero_inds].reshape(-1) \n",
    "#         # Select the binarized yes/no interaction pairs from the original full data\n",
    "#         # that align with the same pairs in training \n",
    "#         pop = pop_items[zero_inds] # Get the item popularity for our chosen items\n",
    "#         store_auc.append(auc_score(pred, actual)) # Calculate AUC for the given user and store\n",
    "#         popularity_auc.append(auc_score(pop, actual)) # Calculate AUC using most popular and score\n",
    "#     # End users iteration\n",
    "    \n",
    "#     return float('%.3f'%np.mean(store_auc)), float('%.3f'%np.mean(popularity_auc))  \n",
    "#    # Return the mean AUC rounded to three decimal places for both test and popularity benchmark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def make_train(ratings, pct_test = 0.2):\n",
    "#     '''\n",
    "#     This function will take in the original user-item matrix and \"mask\" a percentage of the original ratings where a\n",
    "#     user-item interaction has taken place for use as a test set. The test set will contain all of the original ratings, \n",
    "#     while the training set replaces the specified percentage of them with a zero in the original ratings matrix. \n",
    "    \n",
    "#     parameters: \n",
    "    \n",
    "#     ratings - the original ratings matrix from which you want to generate a train/test set. Test is just a complete\n",
    "#     copy of the original set. This is in the form of a sparse csr_matrix. \n",
    "    \n",
    "#     pct_test - The percentage of user-item interactions where an interaction took place that you want to mask in the \n",
    "#     training set for later comparison to the test set, which contains all of the original ratings. \n",
    "    \n",
    "#     returns:\n",
    "    \n",
    "#     training_set - The altered version of the original data with a certain percentage of the user-item pairs \n",
    "#     that originally had interaction set back to zero.\n",
    "    \n",
    "#     test_set - A copy of the original ratings matrix, unaltered, so it can be used to see how the rank order \n",
    "#     compares with the actual interactions.\n",
    "    \n",
    "#     user_inds - From the randomly selected user-item indices, which user rows were altered in the training data.\n",
    "#     This will be necessary later when evaluating the performance via AUC.\n",
    "#     '''\n",
    "#     test_set = ratings.copy() # Make a copy of the original set to be the test set. \n",
    "#     test_set[test_set != 0] = 1 # Store the test set as a binary preference matrix\n",
    "#     training_set = ratings.copy() # Make a copy of the original data we can alter as our training set. \n",
    "#     nonzero_inds = training_set.nonzero() # Find the indices in the ratings data where an interaction exists\n",
    "#     nonzero_pairs = list(zip(nonzero_inds[0], nonzero_inds[1])) # Zip these pairs together of user,item index into list\n",
    "#     random.seed(0) # Set the random seed to zero for reproducibility\n",
    "#     num_samples = int(np.ceil(pct_test*len(nonzero_pairs))) # Round the number of samples needed to the nearest integer\n",
    "#     samples = random.sample(nonzero_pairs, num_samples) # Sample a random number of user-item pairs without replacement\n",
    "#     user_inds = [index[0] for index in samples] # Get the user row indices\n",
    "#     item_inds = [index[1] for index in samples] # Get the item column indices\n",
    "#     training_set[user_inds, item_inds] = 0 # Assign all of the randomly chosen user-item pairs to zero\n",
    "#     training_set.eliminate_zeros() # Get rid of zeros in sparse array storage after update to save space\n",
    "#     return training_set, test_set, list(set(user_inds)) # Output the unique list of user rows that were altered  \n",
    "\n",
    "# This will return our training set, a test set that has been binarized to 0/1 for purchased/not "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from implicit.evaluation import train_test_split\n",
    "\n",
    "coo_mat = utility_matrix.tocoo()\n",
    "train, test = train_test_split(coo_mat)\n",
    "train_user_items = train.T.tocsr()\n",
    "test_user_items = test.T.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_roc_auc_at_k(model, train_user_items, test_user_items, K=10, show_progress=True):\n",
    "    auc_list = []\n",
    "    lenders_count, loans_count = train_user_items.shape\n",
    "    start = time.time()\n",
    "    \n",
    "    with tqdm.tqdm(total=lenders_count) as progress:\n",
    "        for lender_index, lender in enumerate(lenders_list):\n",
    "            lender_row = np.zeros(loans_count)\n",
    "            for loan_index, score in model.recommend(lender_index, train_user_items, N=K):\n",
    "                lender_row[loan_index] = 1\n",
    "            progress.update(1)\n",
    "\n",
    "            test_lender_row = test_user_items[lender_index, :].toarray()[0]\n",
    "            roc_auc = roc_auc_score(test_lender_row, lender_row)\n",
    "            auc_list.append(roc_auc)\n",
    "    logging.debug(\"generated mean ROC AUC in %0.2fs\", time.time() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# START_DATE = '2000-01-01'\n",
    "# END_DATE = '2015-01-01'\n",
    "\n",
    "# mask = (loans_table['raised_time'] > START_DATE) & (loans_table['raised_time'] <= END_DATE)\n",
    "# plot_data = loans_table.loc[mask]\n",
    "\n",
    "plot_data = loans_table\n",
    "\n",
    "plot_data['raised_time'] = pd.to_datetime(plot_data['raised_time'])\n",
    "plot_data['date_month_year'] = plot_data['raised_time'].dt.to_period(\"M\")\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "g1 = sns.pointplot(x='date_month_year', y='loan_amount', \n",
    "                   data=plot_data)\n",
    "g1.set_xticklabels(g1.get_xticklabels(),rotation=90)\n",
    "g1.set_title(\"Mean Loan by Month Year\", fontsize=15)\n",
    "g1.set_xlabel(\"\")\n",
    "g1.set_ylabel(\"Loan Amount\", fontsize=12)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
